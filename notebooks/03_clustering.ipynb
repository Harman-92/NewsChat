{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-24T14:13:19.990910903Z",
     "start_time": "2026-01-24T14:13:19.940551810Z"
    }
   },
   "source": "%run 00_utils.ipynb",
   "outputs": [],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T07:15:50.022843768Z",
     "start_time": "2026-01-23T07:15:49.989874830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas(desc=\"Processing DataFrame\")"
   ],
   "id": "428c9369947fff5c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:38:02.813750368Z",
     "start_time": "2026-01-24T08:38:02.305992626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ],
   "id": "a09b812883c38ca1",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:35:09.691888757Z",
     "start_time": "2026-01-24T12:35:09.633435848Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 240,
   "source": [
    "from openai import OpenAI\n",
    "oa_client = OpenAI()"
   ],
   "id": "db4f8c5a487925c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:51:50.201092121Z",
     "start_time": "2026-01-24T09:51:49.954479966Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 171,
   "source": [
    "import litellm\n",
    "from litellm import completion\n",
    "import instructor\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from instructor.utils import disable_pydantic_error_url\n",
    "from textwrap import dedent"
   ],
   "id": "4f61fe5e0c9ed1ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:51:50.750615967Z",
     "start_time": "2026-01-24T09:51:50.704344626Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 172,
   "source": [
    "#litellm._turn_on_debug()\n",
    "litellm.drop_params = True\n",
    "disable_pydantic_error_url()\n",
    "\n",
    "# Initialize the instructor client\n",
    "client = instructor.from_litellm(completion)"
   ],
   "id": "b9f8bf5374f818bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Tuple"
   ],
   "id": "685120c725a459ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T04:43:33.399574987Z",
     "start_time": "2026-01-23T04:43:31.758590857Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307 entries, 0 to 306\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   url          307 non-null    object             \n",
      " 1   source       307 non-null    object             \n",
      " 2   title        307 non-null    object             \n",
      " 3   description  307 non-null    object             \n",
      " 4   author       307 non-null    object             \n",
      " 5   published    307 non-null    datetime64[ns, UTC]\n",
      " 6   summary      307 non-null    object             \n",
      " 7   category     307 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), object(7)\n",
      "memory usage: 19.3+ KB\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "# Get data from Sheets\n",
    "df_classify = sheets_to_df(\"data_classify\", SHEET_URL)\n",
    "df_classify['published'] = pd.to_datetime(df_classify['published'], utc=True, errors='coerce')\n",
    "df_classify.info()"
   ],
   "id": "1f68a75642814bb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T04:43:48.284974068Z",
     "start_time": "2026-01-23T04:43:48.202996262Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 url source  \\\n",
       "0  https://www.espn.com.au/tennis/story/_/id/4767...   ESPN   \n",
       "1  https://www.espn.com.au/tennis/story/_/id/4769...   ESPN   \n",
       "2  https://www.espn.com.au/golf/story/_/id/476898...   ESPN   \n",
       "3  https://www.espn.com.au/nba/story/_/id/4768975...   ESPN   \n",
       "4  https://www.espn.com.au/afl/story/_/id/4768933...   ESPN   \n",
       "\n",
       "                                               title  \\\n",
       "0      ðŸŽ¾AO live: Wawrinka stuns in five-set marathon   \n",
       "1    What was that for?' Osaka asks of terse Cirstea   \n",
       "2  McIlroy to Rahm, Hatton: Pay fines, play Ryder...   \n",
       "3  Giannis cites chemistry, selfish play after routs   \n",
       "4      Hawks break tradition and appoint co-captains   \n",
       "\n",
       "                                         description author  \\\n",
       "0  Novak Djokovic and Jannik Sinner headline a bu...   ESPN   \n",
       "1  Naomi Osaka received a cool response from Sora...   ESPN   \n",
       "2  Rory McIlroy wants Ryder Cup team-mates Jon Ra...     PA   \n",
       "3  Giannis Antetokounmpo says chemistry issues mi...   ESPN   \n",
       "4  Midfielder Jai Newcombe has been elevated to s...   ESPN   \n",
       "\n",
       "                  published  \\\n",
       "0 2026-01-23 04:25:42+00:00   \n",
       "1 2026-01-23 04:25:42+00:00   \n",
       "2 2026-01-23 04:25:42+00:00   \n",
       "3 2026-01-23 04:25:42+00:00   \n",
       "4 2026-01-23 04:25:42+00:00   \n",
       "\n",
       "                                             summary category  \n",
       "0  ðŸŽ¾AO live: Wawrinka stuns in five-set marathon....   Sports  \n",
       "1  What was that for?' Osaka asks of terse Cirste...   Sports  \n",
       "2  McIlroy to Rahm, Hatton: Pay fines, play Ryder...   Sports  \n",
       "3  Giannis cites chemistry, selfish play after ro...   Sports  \n",
       "4  Hawks break tradition and appoint co-captains....   Sports  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.espn.com.au/tennis/story/_/id/4767...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>ðŸŽ¾AO live: Wawrinka stuns in five-set marathon</td>\n",
       "      <td>Novak Djokovic and Jannik Sinner headline a bu...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2026-01-23 04:25:42+00:00</td>\n",
       "      <td>ðŸŽ¾AO live: Wawrinka stuns in five-set marathon....</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.espn.com.au/tennis/story/_/id/4769...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>What was that for?' Osaka asks of terse Cirstea</td>\n",
       "      <td>Naomi Osaka received a cool response from Sora...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2026-01-23 04:25:42+00:00</td>\n",
       "      <td>What was that for?' Osaka asks of terse Cirste...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.espn.com.au/golf/story/_/id/476898...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>McIlroy to Rahm, Hatton: Pay fines, play Ryder...</td>\n",
       "      <td>Rory McIlroy wants Ryder Cup team-mates Jon Ra...</td>\n",
       "      <td>PA</td>\n",
       "      <td>2026-01-23 04:25:42+00:00</td>\n",
       "      <td>McIlroy to Rahm, Hatton: Pay fines, play Ryder...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.espn.com.au/nba/story/_/id/4768975...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>Giannis cites chemistry, selfish play after routs</td>\n",
       "      <td>Giannis Antetokounmpo says chemistry issues mi...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2026-01-23 04:25:42+00:00</td>\n",
       "      <td>Giannis cites chemistry, selfish play after ro...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.espn.com.au/afl/story/_/id/4768933...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>Hawks break tradition and appoint co-captains</td>\n",
       "      <td>Midfielder Jai Newcombe has been elevated to s...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2026-01-23 04:25:42+00:00</td>\n",
       "      <td>Hawks break tradition and appoint co-captains....</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5,
   "source": [
    "#Filter out rows with 'Other' category\n",
    "df= df_classify[df_classify['category'] != 'Other'].reset_index(drop=True)\n",
    "df.head()"
   ],
   "id": "a52ea6eb1b2ea70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T04:43:53.545969272Z",
     "start_time": "2026-01-23T04:43:53.487187970Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   url          201 non-null    object             \n",
      " 1   source       201 non-null    object             \n",
      " 2   title        201 non-null    object             \n",
      " 3   description  201 non-null    object             \n",
      " 4   author       201 non-null    object             \n",
      " 5   published    201 non-null    datetime64[ns, UTC]\n",
      " 6   summary      201 non-null    object             \n",
      " 7   category     201 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), object(7)\n",
      "memory usage: 12.7+ KB\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": "df.info()",
   "id": "d86b30def33bac77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T04:44:09.714083638Z",
     "start_time": "2026-01-23T04:44:09.639174742Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Lifestyle    84\n",
       "Sports       66\n",
       "Finance      33\n",
       "Music        18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7,
   "source": "df.category.value_counts()",
   "id": "cc10499e87ded66c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T04:48:04.839780094Z",
     "start_time": "2026-01-23T04:48:04.788222112Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category   source        \n",
       "Finance    SMH               16\n",
       "           The Guardian      13\n",
       "           SBS                3\n",
       "           Canberra Times     1\n",
       "Lifestyle  The Guardian      54\n",
       "           SMH               20\n",
       "           ABC                5\n",
       "           Canberra Times     3\n",
       "           SBS                2\n",
       "Music      The Guardian      11\n",
       "           SMH                5\n",
       "           ABC                2\n",
       "Sports     ESPN              38\n",
       "           SMH               22\n",
       "           ABC                4\n",
       "           Canberra Times     1\n",
       "           The Guardian       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9,
   "source": "df.groupby('category')['source'].value_counts()",
   "id": "84ea56331ad4d5ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate embeddings for article summaries",
   "id": "d837b8b6b44f9b02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:35:05.308503535Z",
     "start_time": "2026-01-24T12:35:05.243411767Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 239,
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return oa_client.embeddings.create(input = [text], model=model).data[0].embedding"
   ],
   "id": "1d7a91a139c0d269"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T07:18:05.925807873Z",
     "start_time": "2026-01-23T07:16:38.416565528Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing DataFrame:   0%|          | 0/201 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c68b37b92de4695a7d956c803edbf0b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16,
   "source": "df['embedding'] = df['summary'].progress_apply(lambda x: get_embedding(x, model='text-embedding-3-small'))",
   "id": "52581ab908e3648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:36:51.632390088Z",
     "start_time": "2026-01-24T12:36:43.293482373Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data uploaded successfully to sheet: 'data_embeddings'\""
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 242,
   "source": [
    "## Export to Sheets\n",
    "df_to_sheets(df, \"data_embeddings\", SHEET_URL)"
   ],
   "id": "5940cfdde5496e5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T05:20:49.093966584Z",
     "start_time": "2026-01-24T05:20:49.046697734Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129,
   "source": "len(df['embedding'].iloc[0])",
   "id": "a6a6a3020950f5dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Deduplicate articles within each category",
   "id": "680f3ccd0ccdf44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:57:47.880683166Z",
     "start_time": "2026-01-24T10:57:47.820450809Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 202,
   "source": [
    "# ----------------------------\n",
    "# Union-Find (connected components)\n",
    "# ----------------------------\n",
    "def connected_components(n: int, edges: list[Tuple[int, int]]) -> list[list[int]]:\n",
    "    parent = list(range(n))\n",
    "    rank = [0] * n\n",
    "\n",
    "    def find(x: int) -> int:\n",
    "        while parent[x] != x:\n",
    "            parent[x] = parent[parent[x]]\n",
    "            x = parent[x]\n",
    "        return x\n",
    "\n",
    "    def union(a: int, b: int) -> None:\n",
    "        ra, rb = find(a), find(b)\n",
    "        if ra == rb:\n",
    "            return\n",
    "        if rank[ra] < rank[rb]:\n",
    "            parent[ra] = rb\n",
    "        elif rank[ra] > rank[rb]:\n",
    "            parent[rb] = ra\n",
    "        else:\n",
    "            parent[rb] = ra\n",
    "            rank[ra] += 1\n",
    "\n",
    "    for i, j in edges:\n",
    "        union(i, j)\n",
    "\n",
    "    comps = {}\n",
    "    for i in range(n):\n",
    "        root = find(i)\n",
    "        comps.setdefault(root, []).append(i)\n",
    "\n",
    "    return list(comps.values())\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Graph dedupe for one category\n",
    "# ----------------------------\n",
    "def graph_dedupe_category(\n",
    "    X: np.ndarray,\n",
    "    threshold: float,\n",
    "    k: int,\n",
    ") -> list[list[int]]:\n",
    "    n = X.shape[0]\n",
    "    if n < 2:\n",
    "        return []\n",
    "\n",
    "    nn = NearestNeighbors(\n",
    "        n_neighbors=min(k + 1, n),\n",
    "        metric=\"cosine\",\n",
    "    )\n",
    "\n",
    "    nn.fit(X)\n",
    "    dists, nbrs = nn.kneighbors(X)\n",
    "\n",
    "    edges = set()\n",
    "\n",
    "    for i in range(n):\n",
    "        for dist, j in zip(dists[i, 1:], nbrs[i, 1:]):  # skip self\n",
    "            sim = 1.0 - float(dist)\n",
    "            if sim >= threshold:\n",
    "                j = int(j)\n",
    "                a, b = (i, j) if i < j else (j, i)\n",
    "                edges.add((a, b))\n",
    "\n",
    "    clusters = connected_components(n, list(edges))\n",
    "    return [c for c in clusters if len(c) >= 2]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Full pipeline over all categories\n",
    "# ----------------------------\n",
    "def dedupe_all_categories(\n",
    "    df: pd.DataFrame,\n",
    "    threshold: float = 0.7,\n",
    "    k: int = 15,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Input df columns:\n",
    "    (url, author, published, category, source, title, summary, embedding)\n",
    "\n",
    "    Returns:\n",
    "    1) cluster_df columns: [cluster_id, num_articles, url, article_summary]\n",
    "       (one row per article that belongs to a cluster)\n",
    "    2) clustered_articles_df: original df filtered to only clustered articles,\n",
    "       with cluster_id attached\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_rows = []\n",
    "    category_cluster_counters: dict[str, int] = {}\n",
    "\n",
    "    # Keep original row index so we can map cluster_id back\n",
    "    df = df.reset_index(drop=False).rename(columns={\"index\": \"_row_index\"})\n",
    "\n",
    "    for category, df_cat in df.groupby(\"category\", sort=False):\n",
    "        df_cat = df_cat.reset_index(drop=True)\n",
    "\n",
    "        # per-category cluster counter\n",
    "        category_cluster_counters.setdefault(category, 0)\n",
    "\n",
    "        X = np.vstack(df_cat[\"embedding\"].values)\n",
    "        clusters = graph_dedupe_category(\n",
    "            X=X,\n",
    "            threshold=threshold,\n",
    "            k=min(k, len(df_cat) - 1),\n",
    "        )\n",
    "\n",
    "        for cluster in clusters:\n",
    "            cid = category_cluster_counters[category]\n",
    "            cluster_id = f\"{category}_{cid}\"\n",
    "            category_cluster_counters[category] += 1\n",
    "\n",
    "            cluster_size = len(cluster)\n",
    "\n",
    "            for local_i in cluster:\n",
    "                row = df_cat.iloc[local_i]\n",
    "                cluster_rows.append({\n",
    "                    \"cluster_id\": cluster_id,\n",
    "                    \"category\": category,\n",
    "                    \"num_articles\": cluster_size,\n",
    "                    \"url\": row[\"url\"],\n",
    "                    \"article_summary\": row[\"summary\"],\n",
    "                    \"_row_index\": int(row[\"_row_index\"]),\n",
    "                })\n",
    "\n",
    "    cluster_df = pd.DataFrame(cluster_rows, columns=[\"cluster_id\", \"category\", \"num_articles\", \"url\", \"article_summary\", \"_row_index\"])\n",
    "\n",
    "    if cluster_df.empty:\n",
    "        # return empty frames with expected schema\n",
    "        empty_cluster_df = pd.DataFrame(columns=[\"cluster_id\", \"category\", \"num_articles\", \"url\", \"article_summary\"])\n",
    "        empty_clustered_articles_df = df.iloc[0:0].drop(columns=[\"_row_index\"]).copy()\n",
    "        empty_clustered_articles_df[\"cluster_id\"] = None\n",
    "        return empty_cluster_df, empty_clustered_articles_df\n",
    "\n",
    "    # clustered_articles_df = original rows that are in a cluster, with cluster_id\n",
    "    clustered_articles_df = (\n",
    "        df.merge(\n",
    "            cluster_df[[\"_row_index\", \"cluster_id\"]],\n",
    "            on=\"_row_index\",\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .drop(columns=[\"_row_index\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # final cluster_df with requested columns only\n",
    "    cluster_df = cluster_df.drop(columns=[\"_row_index\"]).reset_index(drop=True)\n",
    "\n",
    "    return cluster_df, clustered_articles_df\n"
   ],
   "id": "881c8f1ea7705941"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:57:48.367298935Z",
     "start_time": "2026-01-24T10:57:48.197895125Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 203,
   "source": "res1, res2 = dedupe_all_categories(df)",
   "id": "a2c51b3878d5831"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:57:49.067724383Z",
     "start_time": "2026-01-24T10:57:48.978826176Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id\n",
       "Lifestyle_0    6\n",
       "Sports_0       5\n",
       "Music_1        3\n",
       "Sports_1       2\n",
       "Sports_2       2\n",
       "Finance_0      2\n",
       "Finance_2      2\n",
       "Finance_1      2\n",
       "Lifestyle_1    2\n",
       "Music_0        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 204,
   "source": "res1['cluster_id'].value_counts()",
   "id": "b7976a37c154c0f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:57:49.515898659Z",
     "start_time": "2026-01-24T10:57:49.420008168Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category   cluster_id \n",
       "Finance    Finance_0      2\n",
       "           Finance_1      2\n",
       "           Finance_2      2\n",
       "Lifestyle  Lifestyle_0    6\n",
       "           Lifestyle_1    2\n",
       "Music      Music_1        3\n",
       "           Music_0        2\n",
       "Sports     Sports_0       5\n",
       "           Sports_1       2\n",
       "           Sports_2       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205,
   "source": "res1.groupby('category')['cluster_id'].value_counts()",
   "id": "180aede95d26f602"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract keywords from article summaries",
   "id": "f1b1d37aa68c158e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:21:22.064848015Z",
     "start_time": "2026-01-24T09:21:22.004793178Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 167,
   "source": [
    "ALLOWED_POS = {\"NOUN\", \"ADJ\"}\n",
    "ALLOWED_ENTS = {\"ORG\", \"PERSON\", \"GPE\", \"EVENT\", \"LOC\"}\n",
    "\n",
    "def normalize_entities(text: str) -> str:\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"[^a-z0-9]+\", \"_\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_possessive_entity(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Splits a possessive entity expression into its components.\n",
    "\n",
    "    This function takes a text string containing a possessive entity (e.g., \"Trump's Greenland\")\n",
    "    and splits it into its constituent components, normalizing each part. The possessive\n",
    "    marker \"'s\" (or \"â€™s\") is removed, and the resulting components are filtered to exclude\n",
    "    empty strings.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing a possessive entity.\n",
    "\n",
    "    Returns:\n",
    "        A list of normalized components of the possessive expression, excluding empty strings.\n",
    "    \"\"\"\n",
    "    # Split once: \"Trump's Greenland\" -> [\"Trump\", \" Greenland\"]\n",
    "    parts = re.split(r\"(?:'s|â€™s)\\b\", text, maxsplit=1)\n",
    "    out = [normalize_entities(p) for p in parts]\n",
    "    return [x for x in out if x]\n",
    "\n",
    "\n",
    "def extract_keywords(text: str) -> list[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract entities\n",
    "    entities: list[str] = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in ALLOWED_ENTS:\n",
    "            continue\n",
    "\n",
    "        if re.search(r\"(?:'s|â€™s)\\b\", ent.text):\n",
    "            entities.extend(split_possessive_entity(ent.text))\n",
    "        else:\n",
    "            norm = normalize_entities(ent.text)\n",
    "            if norm:\n",
    "                entities.append(norm)\n",
    "\n",
    "    # Extract lemmas from allowed POS\n",
    "    lemmas = [\n",
    "        t.lemma_.lower()\n",
    "        for t in doc\n",
    "        if t.pos_ in ALLOWED_POS\n",
    "        and not t.is_stop\n",
    "        and not t.like_num\n",
    "        and t.is_alpha\n",
    "    ]\n",
    "    sorted_lemmas = [w for w, _ in Counter(lemmas).most_common()]\n",
    "\n",
    "    # Merge entities and lemmas, keeping only unique terms\n",
    "    seen = set()\n",
    "    combined: list[str] = []\n",
    "    for term in entities + sorted_lemmas:\n",
    "        if term and term not in seen:\n",
    "            seen.add(term)\n",
    "            combined.append(term)\n",
    "\n",
    "    return combined[:10]"
   ],
   "id": "e41625c8549a61b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T11:11:07.378499423Z",
     "start_time": "2026-01-24T11:11:07.050452289Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing DataFrame:   0%|          | 0/28 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c8932162c03454dbe900c4d389526cd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 207,
   "source": "res1['keywords'] = res1['article_summary'].progress_apply(lambda x: extract_keywords(x))",
   "id": "5b6d7e7d57b16be5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:01:46.979911071Z",
     "start_time": "2026-01-24T12:01:46.913315208Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [osaka, cirstea, naomi_osaka, sorana_cirstea, ...\n",
       "1     [osaka, naomi_osaka, sorana_cirstea, opponent,...\n",
       "2     [osaka, cirstea, naomi_osaka, sorana_cirstea, ...\n",
       "3     [osaka, naomi_osaka, sorana_cirstea, handshake...\n",
       "4     [osaka, naomi_osaka, sorana_cirstea, clash, ri...\n",
       "5     [aus_open, maddison_inglis, emotional, open, w...\n",
       "6     [australia, maddison_inglis, laura_siegemund, ...\n",
       "7     [stan_wawrinka, arthur_gea, frenchman, cool, f...\n",
       "8     [stan_wawrinka, arthur_gea, set, force, ridicu...\n",
       "9     [ricardo_goncalves, johnathan_mcmenamin, barre...\n",
       "10    [rba, australia, the_reserve_bank, rate, stron...\n",
       "11    [trump, australia, donald_trump, greenland, s_...\n",
       "12    [asx, trump, greenland, australia, slide, sink...\n",
       "13    [litchfield, litchfield_minerals, silver_valle...\n",
       "14    [litchfield, nt, litchfield_minerals, ip, copp...\n",
       "15    [david, victoria_beckham, emma_brockes, brookl...\n",
       "16    [david_beckham, brooklyn, child, mistake, soci...\n",
       "17    [beckham, brooklyn, brooklyn_peltz_beckham, da...\n",
       "18    [brooklyn, rich, lady_becks, instagram, david,...\n",
       "19    [beckham, brooklyn, victoria, nicola, boymum, ...\n",
       "20    [brooklyn_beckham, family, tie, famous, parent...\n",
       "21    [plos_one, pgd, pet, owner, grief, study, deat...\n",
       "22    [pgd, plos, pet, grief, death, people, family,...\n",
       "23    [david_byrne, the_talking_heads, flawless, lov...\n",
       "24    [david_byrne, brisbane_entertainment_centre_so...\n",
       "25    [midnight_oil, rob_hirst, drum, ear, flight, k...\n",
       "26    [rob_hirst, midnight_oil, andrew_stafford, dru...\n",
       "27    [rob_hirst, midnight_oil, band, drummer, membe...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 231,
   "source": "res1['keywords']",
   "id": "18cb07da1a08a267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate cluster title and summary using LLM",
   "id": "f7027f6b59c0b555"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:51:53.098517851Z",
     "start_time": "2026-01-24T09:51:53.057865150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sanitise_inputs(inputs: dict) -> dict:\n",
    "    del inputs['response_model']\n",
    "    return inputs\n",
    "\n",
    "@traceable(name='LLMRun', run_type='llm', process_inputs=sanitise_inputs)\n",
    "@retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=10, max=60))\n",
    "def get_llm_response(\n",
    "        messages: list[dict[str, str]],\n",
    "        ls_provider=\"openai\",\n",
    "        ls_model_name=\"gpt-4.1\",\n",
    "        temperature=0,\n",
    "        seed=None,\n",
    "        response_model=None,\n",
    "        max_retries=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to get a response from the OpenAI compatible completion endpoints using litellm and instructor.\n",
    "    Includes retry logic for rate limits as well as tracing with langsmith.\n",
    "    \"\"\"\n",
    "\n",
    "    model = f\"{ls_provider}/{ls_model_name}\"\n",
    "\n",
    "    params = {\n",
    "        \"messages\": messages,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    if seed is not None:\n",
    "        params[\"seed\"] = seed\n",
    "\n",
    "    if response_model is not None:\n",
    "        # Instructor structured outputs\n",
    "        params[\"response_model\"] = response_model\n",
    "\n",
    "        # Set number of retries incase output does not match the response_model\n",
    "        params[\"max_retries\"] = max_retries\n",
    "        return client.chat.completions.create(**params)\n",
    "\n",
    "    return completion.create(**params)"
   ],
   "id": "55e4591eef580f2e",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:02:21.224692467Z",
     "start_time": "2026-01-24T10:02:21.167980622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the classification prompt and response model\n",
    "story_prompt = dedent(f\"\"\"\n",
    "You will be presented with a list of news articles belonging to the same news story cluster.\n",
    "Your task is to extract <title> and <summary> of the cluster that accurately repesents the story.\n",
    "\n",
    "Guidelines:\n",
    "- You must only use the information and facts provided in the articles.\n",
    "- <title> should be a concise headline (less than 8 words) for the news story cluster in Australian Spelling. Use sentence case.\n",
    "- <summary> should be an accurate summary including relevant information and entities in Australian Spelling. Length should be between 30-50 words.\n",
    "\"\"\")\n",
    "\n",
    "class StoryResponse(BaseModel):\n",
    "    title: str = Field(\n",
    "        ...,\n",
    "        description=\"Short title of the given news cluster in Australian Spelling. Use sentence case. Must be less than 8 words.\",\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        ...,\n",
    "        description=\"Summary of the given news cluster in Australian Spelling. Length should be between 30-50 words.\",\n",
    "    )"
   ],
   "id": "88bdf021fae3e957",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T10:01:23.111246356Z",
     "start_time": "2026-01-24T10:01:23.073771329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tool to get content for story cluster\n",
    "@traceable(name='ClusterContent', run_type='tool')\n",
    "def get_cluster_data(articles: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": story_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Articles:\\n----\\n{articles}\"}\n",
    "    ]\n",
    "    model_params = {\n",
    "            \"ls_provider\": \"openai\",\n",
    "            \"ls_model_name\": \"gpt-4.1\"\n",
    "        }\n",
    "    response = get_llm_response(\n",
    "        messages=messages,\n",
    "        **model_params,\n",
    "        seed=42,\n",
    "        response_model=StoryResponse,\n",
    "        langsmith_extra={\n",
    "            'metadata': {\n",
    "                'ls_provider': model_params['ls_provider'],\n",
    "                'ls_model_name': model_params['ls_model_name']\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response"
   ],
   "id": "88726b1a8d066d6e",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Aggregate cluster data",
   "id": "40a3b47d64d718c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T11:44:18.733467384Z",
     "start_time": "2026-01-24T11:44:18.696764659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mode_or_none(s: pd.Series):\n",
    "    m = s.mode()\n",
    "    return m.iloc[0] if not m.empty else None\n",
    "\n",
    "def generate_cluster_content(summaries: pd.Series) -> dict:\n",
    "    texts = \"\\n----\\n\".join(summaries.tolist())\n",
    "\n",
    "    # Generate using llm\n",
    "    res = get_cluster_data(texts)\n",
    "    return res\n",
    "\n",
    "\n",
    "def top_keywords_tf(keywords: pd.Series, top_n: int = 10) -> list[str]:\n",
    "    c = Counter()\n",
    "    for kws in keywords.dropna():\n",
    "        if isinstance(kws, list):\n",
    "            c.update(kws)\n",
    "    return [k for k, _ in c.most_common(top_n)]\n",
    "\n",
    "\n",
    "def aggregate_cluster_df(cluster_df: pd.DataFrame, top_n_keywords: int = 10) -> pd.DataFrame:\n",
    "    agg = (\n",
    "        cluster_df\n",
    "        .groupby(\"cluster_id\", as_index=False)\n",
    "        .agg(\n",
    "            category=(\"category\", mode_or_none),\n",
    "            num_articles=(\"num_articles\", mode_or_none),\n",
    "            content=(\"article_summary\", generate_cluster_content),\n",
    "            keywords=(\"keywords\", lambda s: top_keywords_tf(s, top_n=top_n_keywords)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # split dict into columns\n",
    "    agg[\"title\"] = agg[\"content\"].map(lambda d: d.title)\n",
    "    agg[\"summary\"] = agg[\"content\"].map(lambda d: d.summary)\n",
    "    agg = agg.drop(columns=[\"content\"])\n",
    "\n",
    "    return agg\n"
   ],
   "id": "a4d30c230c73dcd7",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T11:44:37.914475150Z",
     "start_time": "2026-01-24T11:44:19.789487398Z"
    }
   },
   "cell_type": "code",
   "source": "clusters = aggregate_cluster_df(res1)",
   "id": "ef93859913182f0b",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:35:19.920221629Z",
     "start_time": "2026-01-24T12:35:15.882366995Z"
    }
   },
   "cell_type": "code",
   "source": "clusters['embedding'] = clusters['summary'].progress_apply(lambda x: get_embedding(x, model='text-embedding-3-small'))",
   "id": "243d0927f897826a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing DataFrame:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5e204444f854646a9c51c3ffbeceef1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:27:22.340212712Z",
     "start_time": "2026-01-24T12:27:22.214517132Z"
    }
   },
   "cell_type": "code",
   "source": "clusters.info()",
   "id": "253f1b098bfc124e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   cluster_id    10 non-null     object\n",
      " 1   category      10 non-null     object\n",
      " 2   num_articles  10 non-null     int64 \n",
      " 3   keywords      10 non-null     object\n",
      " 4   title         10 non-null     object\n",
      " 5   summary       10 non-null     object\n",
      " 6   embedding     10 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 692.0+ bytes\n"
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:39:09.038028828Z",
     "start_time": "2026-01-24T12:39:08.983385640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## Export to Sheets\n",
    "# df_to_sheets(clusters, \"clusters_db\", SHEET_URL)"
   ],
   "id": "82f4c526472fe033",
   "outputs": [],
   "execution_count": 247
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:43:29.365035956Z",
     "start_time": "2026-01-24T12:43:29.265047173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "articles = res2.copy()\n",
    "articles.drop(columns=[\"description\"], inplace=True)\n",
    "articles.info()"
   ],
   "id": "520105fb542f0523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   url         28 non-null     object             \n",
      " 1   source      28 non-null     object             \n",
      " 2   title       28 non-null     object             \n",
      " 3   author      28 non-null     object             \n",
      " 4   published   28 non-null     datetime64[ns, UTC]\n",
      " 5   summary     28 non-null     object             \n",
      " 6   category    28 non-null     object             \n",
      " 7   embedding   28 non-null     object             \n",
      " 8   cluster_id  28 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](1), object(8)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T12:43:51.375287784Z",
     "start_time": "2026-01-24T12:43:51.338259994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## Export to Sheets\n",
    "# df_to_sheets(articles, \"articles_db\", SHEET_URL)"
   ],
   "id": "c0aeb32f4d0a5edc",
   "outputs": [],
   "execution_count": 250
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Export data to Weaviate Cloud",
   "id": "c3656f6b89bf243b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:22:27.519693881Z",
     "start_time": "2026-01-24T14:22:27.475127360Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 265,
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weaviate\n",
    "from weaviate.util import generate_uuid5\n",
    "from weaviate.classes.config import (\n",
    "    Configure,\n",
    "    DataType,\n",
    "    Property,\n",
    "    ReferenceProperty,\n",
    "    VectorDistances,\n",
    ")"
   ],
   "id": "4d8a802186254967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ARTICLE_COL = \"Article\"\n",
    "CLUSTER_COL = \"Cluster\"\n",
    "\n",
    "\n",
    "def to_rfc3339(val: Any) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Converts input to RFC3339 UTC string, or None if invalid.\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "\n",
    "    return val.isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "\n",
    "def keywords_to_text(kw: Any) -> str:\n",
    "    \"\"\"\n",
    "    Converts keywords input to a single text string.\n",
    "    \"\"\"\n",
    "    if kw is None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return \" \".join(kw)\n",
    "\n",
    "\n",
    "def uuid_for_article(url: str) -> str:\n",
    "    return str(generate_uuid5(url))\n",
    "\n",
    "\n",
    "def uuid_for_cluster(cluster_id: str) -> str:\n",
    "    return str(generate_uuid5(f\"cluster::{cluster_id}\"))\n",
    "\n",
    "\n",
    "def create_schema(client: weaviate.WeaviateClient) -> None:\n",
    "    \"\"\"\n",
    "    Creates the required Weaviate schema for Article and Cluster collections.\n",
    "    \"\"\"\n",
    "    # 1) Create Article collection\n",
    "    if not client.collections.exists(ARTICLE_COL):\n",
    "        client.collections.create(\n",
    "            name=ARTICLE_COL,\n",
    "            properties=[\n",
    "                Property(name=\"url\", data_type=DataType.TEXT),\n",
    "                Property(name=\"source\", data_type=DataType.TEXT),\n",
    "                Property(name=\"title\", data_type=DataType.TEXT),\n",
    "                Property(name=\"author\", data_type=DataType.TEXT),\n",
    "                Property(name=\"published\", data_type=DataType.DATE),\n",
    "                Property(name=\"summary\", data_type=DataType.TEXT),\n",
    "                Property(name=\"category\", data_type=DataType.TEXT),\n",
    "                Property(name=\"cluster_id\", data_type=DataType.TEXT),\n",
    "            ],\n",
    "            vector_config=Configure.Vectors.self_provided(\n",
    "                vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                    distance_metric=VectorDistances.COSINE\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # 2) Create Cluster collection\n",
    "    if not client.collections.exists(CLUSTER_COL):\n",
    "        client.collections.create(\n",
    "            name=CLUSTER_COL,\n",
    "            properties=[\n",
    "                Property(name=\"cluster_id\", data_type=DataType.TEXT),\n",
    "                Property(name=\"category\", data_type=DataType.TEXT),\n",
    "                Property(name=\"num_articles\", data_type=DataType.INT),\n",
    "                Property(name=\"keywords\", data_type=DataType.TEXT),\n",
    "                Property(name=\"title\", data_type=DataType.TEXT),\n",
    "                Property(name=\"summary\", data_type=DataType.TEXT),\n",
    "            ],\n",
    "            vector_config=Configure.Vectors.self_provided(\n",
    "                vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                    distance_metric=VectorDistances.COSINE\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # 3) Add references (Optional)\n",
    "    Article = client.collections.get(ARTICLE_COL)\n",
    "    Cluster = client.collections.get(CLUSTER_COL)\n",
    "\n",
    "    # Add Cluster.articles -> Article (if missing)\n",
    "    Cluster.config.add_reference(ReferenceProperty(name=\"articles\", target_collection=ARTICLE_COL))\n",
    "\n",
    "    # Add Article.cluster -> Cluster (if missing)\n",
    "    Article.config.add_reference(ReferenceProperty(name=\"cluster\", target_collection=CLUSTER_COL))"
   ],
   "id": "bd09dbd1041076f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass(frozen=True)\n",
    "class LoadStats:\n",
    "    clusters_written: int\n",
    "    articles_written: int\n",
    "    refs_written: int\n",
    "\n",
    "\n",
    "def load_dataframes_to_weaviate(\n",
    "    client: weaviate.WeaviateClient,\n",
    "    *,\n",
    "    clusters_df: pd.DataFrame,\n",
    "    articles_df: pd.DataFrame,\n",
    "    cluster_embedding_col: str = \"embedding\",\n",
    "    article_embedding_col: str = \"embedding\",\n",
    "    batch_size: int = 256,\n",
    ") -> LoadStats:\n",
    "    \"\"\"\n",
    "    Loads clusters and articles dataframes into Weaviate.\n",
    "    \"\"\"\n",
    "\n",
    "    create_schema(client)\n",
    "\n",
    "    Cluster = client.collections.get(CLUSTER_COL)\n",
    "    Article = client.collections.get(ARTICLE_COL)\n",
    "\n",
    "    # ---- 0) minimal sanitization (cheap + safe) ----\n",
    "    # Ensure strings are strings, keywords become text\n",
    "    clusters = clusters_df.copy()\n",
    "    clusters[\"cluster_id\"] = clusters[\"cluster_id\"].astype(str)\n",
    "    clusters[\"keywords\"] = clusters[\"keywords\"].apply(keywords_to_text)\n",
    "\n",
    "    articles = articles_df.copy()\n",
    "    articles[\"url\"] = articles[\"url\"].astype(str)\n",
    "    articles[\"cluster_id\"] = articles[\"cluster_id\"].astype(str)\n",
    "\n",
    "    # Convert published to RFC3339 once to avoid doing it repeatedly in loop\n",
    "    articles[\"published_rfc3339\"] = articles[\"published\"].apply(to_rfc3339)\n",
    "\n",
    "\n",
    "    # ---- 1) Insert clusters ----\n",
    "    clusters_written = 0\n",
    "    with Cluster.batch.dynamic() as batch:\n",
    "        batch.batch_size = batch_size\n",
    "        for row in clusters.itertuples(index=False):\n",
    "            cid = str(getattr(row, \"cluster_id\"))\n",
    "            uuid = uuid_for_cluster(cid)\n",
    "\n",
    "            vec = getattr(row, cluster_embedding_col)\n",
    "\n",
    "            props = {\n",
    "                \"cluster_id\": cid,\n",
    "                \"category\": getattr(row, \"category\", \"\") or \"\",\n",
    "                \"num_articles\": int(getattr(row, \"num_articles\", 0) or 0),\n",
    "                \"keywords\": getattr(row, \"keywords\", \"\") or \"\",\n",
    "                \"title\": getattr(row, \"title\", \"\") or \"\",\n",
    "                \"summary\": getattr(row, \"summary\", \"\") or \"\",\n",
    "            }\n",
    "\n",
    "            batch.add_object(uuid=uuid, properties=props, vector=vec)\n",
    "            clusters_written += 1\n",
    "\n",
    "    # ---- 2) Insert articles ----\n",
    "    articles_written = 0\n",
    "    with Article.batch.dynamic() as batch:\n",
    "        batch.batch_size = batch_size\n",
    "        for row in articles.itertuples(index=False):\n",
    "            url = str(getattr(row, \"url\"))\n",
    "            uuid = uuid_for_article(url)\n",
    "\n",
    "            vec = getattr(row, article_embedding_col)\n",
    "            published = getattr(row, \"published_rfc3339\")\n",
    "\n",
    "            props = {\n",
    "                \"url\": url,\n",
    "                \"source\": getattr(row, \"source\", \"\") or \"\",\n",
    "                \"title\": getattr(row, \"title\", \"\") or \"\",\n",
    "                \"author\": getattr(row, \"author\", \"\") or \"\",\n",
    "                \"published\": published,\n",
    "                \"summary\": getattr(row, \"summary\", \"\") or \"\",\n",
    "                \"category\": getattr(row, \"category\", \"\") or \"\",\n",
    "                \"cluster_id\": str(getattr(row, \"cluster_id\") or \"\"),\n",
    "            }\n",
    "\n",
    "            batch.add_object(uuid=uuid, properties=props, vector=vec)\n",
    "            articles_written += 1\n",
    "\n",
    "    refs_written = 0\n",
    "\n",
    "    for row in articles[[\"url\", \"cluster_id\"]].itertuples(index=False):\n",
    "        url = str(row.url)\n",
    "        cid = str(row.cluster_id)\n",
    "\n",
    "        if not cid:\n",
    "            continue\n",
    "\n",
    "        c_uuid = uuid_for_cluster(cid)\n",
    "        a_uuid = uuid_for_article(url)\n",
    "\n",
    "        # Cluster -> articles (one-to-many): add an edge\n",
    "        Cluster.data.reference_add(\n",
    "            from_uuid=c_uuid,\n",
    "            from_property=\"articles\",\n",
    "            to=a_uuid\n",
    "        )\n",
    "\n",
    "        # Article -> cluster (one-to-one): replace/set the reference\n",
    "        Article.data.reference_replace(\n",
    "            from_uuid=a_uuid,\n",
    "            from_property=\"cluster\",\n",
    "            to=c_uuid\n",
    "        )\n",
    "\n",
    "        refs_written += 2\n",
    "\n",
    "    return LoadStats(\n",
    "        clusters_written=clusters_written,\n",
    "        articles_written=articles_written,\n",
    "        refs_written=refs_written,\n",
    "    )"
   ],
   "id": "4ff725baa8e85cea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:24:14.343130179Z",
     "start_time": "2026-01-24T14:24:14.322137687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "\n",
    "weaviate_url = os.environ[\"WEAVIATE_ENDPOINT\"]\n",
    "weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "w_client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")"
   ],
   "id": "f767b8e694bde382",
   "outputs": [],
   "execution_count": 268
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:22:35.496559689Z",
     "start_time": "2026-01-24T14:22:33.032787940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stats = load_dataframes_to_weaviate(\n",
    "    w_client,\n",
    "    clusters_df=clusters,\n",
    "    articles_df=articles,\n",
    "    cluster_embedding_col=\"embedding\",\n",
    "    article_embedding_col=\"embedding\",\n",
    "    batch_size=256,\n",
    ")"
   ],
   "id": "7743d9e1895d6016",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:24:30.636642175Z",
     "start_time": "2026-01-24T14:24:30.603769511Z"
    }
   },
   "cell_type": "code",
   "source": "print(stats)",
   "id": "6962316f8a86d32f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadStats(clusters_written=10, articles_written=28, refs_written=56)\n"
     ]
    }
   ],
   "execution_count": 269
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T14:23:57.461696939Z",
     "start_time": "2026-01-24T14:23:57.408266953Z"
    }
   },
   "cell_type": "code",
   "source": "w_client.close()",
   "id": "d33c30cde86207e8",
   "outputs": [],
   "execution_count": 267
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b61ed5c81fd32eb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
